{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.init as init\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('data/movies_data.csv')\n",
    "ratings_df = pd.read_csv('data/ratings_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.merge(left=ratings_df, right=movies_df[['title','id']], left_on='movieId', right_on='id', how='left').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieid_to_idx = {mid: idx for idx, mid in enumerate(ratings_df['movieId'].unique())}\n",
    "ratings_df['lookup_id'] = ratings_df['movieId'].map(movieid_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_name_to_loopup_id = {row['title']:row['lookup_id'] for idx, row in ratings_df[['title', 'lookup_id']].drop_duplicates().iterrows()}\n",
    "idx_to_movie_name = {idx:name for name, idx in movie_name_to_loopup_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, ratings_df: pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.users = ratings_df['userId'].values\n",
    "        self.movies = ratings_df['lookup_id'].values\n",
    "        self.ratings = ratings_df['rating'].values\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        user = torch.tensor(self.users[index], dtype=torch.int32)\n",
    "        movie = torch.tensor(self.movies[index], dtype=torch.int32)\n",
    "        rating = torch.tensor(self.ratings[index], dtype=torch.float32)\n",
    "\n",
    "        return user, movie, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, embed_dim, n_users, n_movies):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.user_matrix = nn.Embedding(n_users, embed_dim)     # u x d\n",
    "        self.movies_matrix = nn.Embedding(n_movies, embed_dim)  # m x d\n",
    "\n",
    "        # Initialize parameters to small random numbers\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Xavier initialization for embeddings\n",
    "        nn.init.xavier_uniform_(self.user_matrix.weight)\n",
    "        nn.init.xavier_uniform_(self.movies_matrix.weight)\n",
    "\n",
    "    def forward(self, users, movies):\n",
    "        users = self.user_matrix(users)         # b x d\n",
    "        movies = self.movies_matrix(movies)     # b x d\n",
    "        \n",
    "        affinities = torch.sum(users * movies, dim=1) / math.sqrt(self.embed_dim)  # b x 1\n",
    "\n",
    "        return affinities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        return torch.sqrt(torch.mean((predictions - targets) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024 * 256\n",
    "train_set = CustomDataset(ratings_df)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size ,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings_df['userId'].nunique() \n",
    "num_movies = ratings_df['movieId'].nunique() \n",
    "\n",
    "model = MatrixFactorization(4, num_users, num_movies).to(device)\n",
    "loss_fn = RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epocs = 20\n",
    "lambda_reg = 1e-5  # Regularization strength\n",
    "\n",
    "for i in range(Epocs):\n",
    "    \n",
    "\n",
    "    if i < Epocs//2:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "    for _, (users, movies, y) in enumerate(train_loader):\n",
    "    \n",
    "        pred_ratings = model(users.to(device), movies.to(device))\n",
    "        loss = loss_fn(pred_ratings.to(device), y.to(device))\n",
    "\n",
    "        \n",
    "        l2_reg = sum(param.pow(2).sum() for param in model.parameters())/sum(p.nelement() for p in model.parameters())  \n",
    "        loss = loss + lambda_reg * l2_reg\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"parameters/collaboative_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"parameters/collaboative_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\n",
    "    ['The Sixth Sense 1999', 5],\n",
    "    ['Se7en 1995', 5],\n",
    "    ['Men in Black 1997', 4],\n",
    "]\n",
    "watched_movies = [movie[0] for movie in my_list]\n",
    "my_list = [ [movie_name_to_loopup_id[movie[0]], movie[1]]   for movie in my_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.movies_matrix.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(name):\n",
    "    return movies_df[movies_df['title'] == name]['vote_count'].values[0]\n",
    "idx_to_movie_name = {idx:name for name, idx in movie_name_to_loopup_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg = 1e-4  # Regularization strength\n",
    "class NewUser(nn.Module):\n",
    "    def __init__(self, user):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seen_movies = torch.tensor([movie[0] for movie in user], dtype=torch.int32).to(device)\n",
    "        self.given_ratings = torch.tensor([movie[1] for movie in user], dtype=torch.float32).to(device)\n",
    "        self.given_ratings = self.given_ratings - self.given_ratings.mean()\n",
    "\n",
    "        self.movie_embeddings = model.movies_matrix(self.seen_movies)\n",
    "\n",
    "        \n",
    "        self.user = torch.randn((1, model.embed_dim), requires_grad=True, device=device)\n",
    "        \n",
    "        \n",
    "        init.xavier_normal_(self.user)\n",
    "        self.user = self.user.detach().requires_grad_()\n",
    "\n",
    "        self.epocs = 500\n",
    "        self.train_user()\n",
    "\n",
    "    def train_user(self):\n",
    "        model.movies_matrix.weight.requires_grad = False\n",
    "        \n",
    "        optimizer = torch.optim.Adam([self.user], lr=1e-1)\n",
    "\n",
    "        for i in range(self.epocs):\n",
    "            \n",
    "            affinity = torch.sum(self.user * self.movie_embeddings, dim=1) / math.sqrt(model.embed_dim)\n",
    "\n",
    "            l2_reg = self.user.sum().pow(2) / model.embed_dim\n",
    "            loss = loss_fn(affinity, self.given_ratings) + lambda_reg * l2_reg\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Final user Loss: {loss.item():.4f}')\n",
    "\n",
    "    def recommed(self, n_movies = 5):\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            user_matrix = model.user_matrix.weight.detach().cpu().numpy()\n",
    "            cur_user = self.user.detach().cpu().numpy()\n",
    "\n",
    "            # Getting User Similarities\n",
    "            matrix_norms = np.linalg.norm(user_matrix, axis= 1)\n",
    "            vector_norm = np.linalg.norm(cur_user, axis = 1)\n",
    "            dot_products = (user_matrix @ cur_user.T).flatten() \n",
    "            cosine_similarities = dot_products / (matrix_norms * vector_norm)\n",
    "\n",
    "            # Selecting Top 20 Users\n",
    "            topk = 20\n",
    "            ids = np.argsort(-cosine_similarities)[:topk]\n",
    "            similar_users = ratings_df[ratings_df['userId'].isin(ids)]\n",
    "            similar_users = similar_users.pivot(index='userId', columns='title', values= 'rating')\n",
    "            movie_names = similar_users.columns.tolist()\n",
    "\n",
    "            # Ordering movies based on Avg votes of the top 20 similar users\n",
    "            avg_votes = np.nanmean(similar_users.values, axis = 0)\n",
    "            num_votes = (np.sum(~np.isnan(similar_users.values), axis = 0) >= topk * 0.75)\n",
    "            filtered_votes = num_votes*avg_votes\n",
    "            top_movies = np.argsort(-filtered_votes).tolist()[:10]\n",
    "            x = [movie_names[id] for id in top_movies if movie_names[id] not in watched_movies]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final user Loss: 0.0417\n"
     ]
    }
   ],
   "source": [
    "n = NewUser(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20,000 Leagues Under the Sea 1997',\n",
       " 'Men in Black II 2002',\n",
       " 'Once Were Warriors 1994',\n",
       " 'Point Break 1991',\n",
       " 'Rush Hour 1998',\n",
       " 'Scarface 1983',\n",
       " 'Scary Movie 2000',\n",
       " 'Secret Window 2004',\n",
       " 'Sleepless in Seattle 1993',\n",
       " 'Solaris 1972']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = n.recommed()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
